{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f15c47",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cece655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import contours\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd23e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"final1.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0c9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbcd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a451c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dilate = cv2.dilate(thresh1, None, iterations=1)\n",
    "dilate = cv2.dilate(thresh1, rect_kern, iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a522cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_digits_and_symbols(dilate, charCnts, minW=5, minH=15):\n",
    "    # grab the internal Python iterator for the list of character\n",
    "    # contours, then  initialize the character ROI and location\n",
    "    # lists, respectively\n",
    "    charIter = charCnts.__iter__()\n",
    "    rois = []\n",
    "    locs = []\n",
    "    # keep looping over the character contours until we reach the end\n",
    "    # of the list\n",
    "    while True:\n",
    "        try:\n",
    "            # grab the next character contour from the list, compute\n",
    "            # its bounding box, and initialize the ROI\n",
    "            c = next(charIter)\n",
    "            (cX, cY, cW, cH) = cv2.boundingRect(c)\n",
    "            roi = None\n",
    "            # check to see if the width and height are sufficiently\n",
    "            # large, indicating that we have found a digit\n",
    "            if cW >= minW and cH >= minH:\n",
    "\t\t\t\t# extract the ROI\n",
    "                roi = image[cY:cY + cH, cX:cX + cW]\n",
    "                rois.append(roi)\n",
    "                locs.append((cX, cY, cX + cW, cY + cH))\n",
    "                # otherwise, we are examining one of the special symbols\n",
    "            else:\n",
    "\t\t\t\t# MICR symbols include three separate parts, so we\n",
    "\t\t\t\t# need to grab the next two parts from our iterator,\n",
    "\t\t\t\t# followed by initializing the bounding box\n",
    "\t\t\t\t# coordinates for the symbol\n",
    "                parts = [c, next(charIter), next(charIter)]\n",
    "                (sXA, sYA, sXB, sYB) = (np.inf, np.inf, -np.inf,-np.inf)\n",
    "                # loop over the parts\n",
    "                for p in parts:\n",
    "\t\t\t\t\t# compute the bounding box for the part, then\n",
    "\t\t\t\t\t# update our bookkeeping variables\n",
    "                    (pX, pY, pW, pH) = cv2.boundingRect(p)\n",
    "                    sXA = min(sXA, pX)\n",
    "                    sYA = min(sYA, pY)\n",
    "                    sXB = max(sXB, pX + pW)\n",
    "                    sYB = max(sYB, pY + pH)\n",
    "                # extract the ROI\n",
    "                roi = image[sYA:sYB, sXA:sXB]\n",
    "                rois.append(roi)\n",
    "                locs.append((sXA, sYA, sXB, sYB))\n",
    "                # we have reached the end of the iterator; gracefully break\n",
    "        # from the loop\n",
    "        except StopIteration:\n",
    "            break\n",
    "    # return a tuple of the ROIs and locations\n",
    "    return (rois, locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f84f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refCnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,\n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "refCnts = refCnts[1] if imutils.is_cv3() else refCnts[0]\n",
    "#refCnts = imutils.grab_contours(refCnts)\n",
    "sorted_ctrs = sorted(refCnts, key=lambda ctr: cv2.boundingRect(ctr)[1] + cv2.boundingRect(ctr)[0] * image.shape[0] )\n",
    "#refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "# create a clone of the original image so we can draw on it\n",
    "orig = np.dstack([image.copy()])\n",
    "#orig = image.copy()\n",
    "i=0\n",
    "#clone = np.dstack([dilate.copy()] * 3)\n",
    "# loop over the (sorted) contours\n",
    "for cnt in sorted_ctrs:\n",
    "    # compute the bounding box of the contour and draw it on our\n",
    "    # image\n",
    "    (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "# show the output of applying the simple contour method\n",
    "cv2.imshow(\"Simple Method\", orig)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e657dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "charName  = {'0':'0', 'A':'A', 'B':'B', 'C':\"C\", 'D':'D', 'E':'E', 'F':'F', 'G':'G', 'H':'H', 'I':'I', 'J':'J', 'K':'K', 'L':'L', 'M':'M', 'N':'N', 'O':'O', 'P':'P', 'Q':'Q', 'R':'R', 'S':'S', 'T':'T', 'U':'U', 'V':'V', 'W':'W', 'X':'X', 'Y':'Y','Z':'Z', 'RA':'रा', 'a_':'a', 'b_':'b', 'c_':'c', 'd_':'d', 'e_':'e', 'f_':'f', 'g_':'g', 'h_':'h', 'i_':'i', 'j_':'j', 'k_':'k', 'l_':'l', 'm_':'m', 'n_':'n', 'o_':'o', 'p_':'p', 'q_':'q', 'r_':'r', 's_':'s', 't_':'t', 'u_':'u', 'v_':'v', 'w_':'w', 'x_':'x', 'y_':'y', 'z_':'z', 'kk':'क'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2122c382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the digits and symbols from the list of contours, then\n",
    "# initialize a dictionary to map the character name to the ROI\n",
    "(refROIs, refLocs) = extract_digits_and_symbols(dilate, sorted_ctrs,\n",
    "minW=1, minH=30)\n",
    "chars = {}\n",
    "# re-initialize the clone image so we can draw on it again\n",
    "#clone = np.dstack([ref.copy()] * 3)\n",
    "orig = np.dstack([image.copy()])\n",
    "# gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "# rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "dilate = cv2.dilate(orig, rect_kern, iterations = 3)\n",
    "#orig = dilate.copy()\n",
    "# loop over the reference ROIs and locations\n",
    "for (name, roi, loc) in zip(charName, refROIs, refLocs):\n",
    "    # draw a bounding box surrounding the character on the output\n",
    "    # image\n",
    "    (xA, yA, xB, yB) = loc\n",
    "    cv2.rectangle(dilate, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "    # resize the ROI to a fixed size, then update the characters\n",
    "    # dictionary, mapping the character name to the ROI\n",
    "    roi = cv2.resize(roi, (36, 36)) \n",
    "    chars[name] = roi\n",
    "    # display the character ROI to our screen\n",
    "    cv2.imshow(\"Char\", roi)\n",
    "    cv2.waitKey(0)\n",
    "# show the output of our better method\n",
    "cv2.imshow(\"Better Method\", dilate)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39f3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('dcr1.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"dcr1.h5\")\n",
    "#print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.save('dcr1.hdf5')\n",
    "loaded_model=load_model('dcr1.hdf5')\n",
    "\n",
    "categories  = {'0':'0', 'A':'A', 'B':'B', 'C':\"C\", 'D':'D', 'E':'E', 'F':'F', 'G':'G', 'H':'H', 'I':'I', 'J':'J', 'K':'K', 'L':'L', 'M':'M', 'N':'N', 'O':'O', 'P':'P', 'Q':'Q', 'R':'R', 'S':'S', 'T':'T', 'U':'U', 'V':'V', 'W':'W', 'X':'X', 'Y':'Y','Z':'Z', 'RA':'रा', 'a_':'a', 'b_':'b', 'c_':'c', 'd_':'d', 'e_':'e', 'f_':'f', 'g_':'g', 'h_':'h', 'i_':'i', 'j_':'j', 'k_':'k', 'l_':'l', 'm_':'m', 'n_':'n', 'o_':'o', 'p_':'p', 'q_':'q', 'r_':'r', 's_':'s', 't_':'t', 'u_':'u', 'v_':'v', 'w_':'w', 'x_':'x', 'y_':'y', 'z_':'z', 'kk':'क'} \n",
    "#categories = categories.split(',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3da32f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 15525 into shape (1,64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1d06e3ee17c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 15525 into shape (1,64,64,1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img= image.load_img('C:/Users/bivan/Desktop/preprocessing/Images/roi0.png')\n",
    "plt.imshow(img)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.asarray(img_array, dtype = np.float32).reshape(1, 64, 64, 1) / 255 \n",
    "\n",
    "predictions = loaded_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[-1])\n",
    "\n",
    "print(\n",
    "    \"This image most likely is {} with a {:.2f} percent confidence.\".format(categories[list(categories.keys())[np.argmax(score)]], 100*np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca53c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000002768AA2EF40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpbgirc8kd.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000002768AA2EF40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpbgirc8kd.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "'''from google.colab import files\n",
    "upload = files.upload()'''\n",
    "categories  = {'0':'0', 'A':'A', 'B':'B', 'C':\"C\", 'D':'D', 'E':'E', 'F':'F', 'G':'G', 'H':'H', 'I':'I', 'J':'J', 'K':'K', 'L':'L', 'M':'M', 'N':'N', 'O':'O', 'P':'P', 'Q':'Q', 'R':'R', 'S':'S', 'T':'T', 'U':'U', 'V':'V', 'W':'W', 'X':'X', 'Y':'Y','Z':'Z', 'RA':'रा', 'a_':'a', 'b_':'b', 'c_':'c', 'd_':'d', 'e_':'e', 'f_':'f', 'g_':'g', 'h_':'h', 'i_':'i', 'j_':'j', 'k_':'k', 'l_':'l', 'm_':'m', 'n_':'n', 'o_':'o', 'p_':'p', 'q_':'q', 'r_':'r', 's_':'s', 't_':'t', 'u_':'u', 'v_':'v', 'w_':'w', 'x_':'x', 'y_':'y', 'z_':'z', 'kk':'क'} \n",
    "#categories = categories.split(',')\n",
    "img = cv2.imread(r'C:/Users/bivan/Desktop/preprocessing/Images/roi0.png')\n",
    "img_copy = img.copy()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (150,150))\n",
    "\n",
    "img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "img_final = cv2.resize(img_thresh, (64,64))\n",
    "img_final =np.reshape(img_final, (1,64,64,-1))\n",
    "\n",
    "\n",
    "img_pred = categories[list(categories.keys())[np.argmax(loaded_model.predict(img_final))]]\n",
    "#score = tf.nn.softmax(img_pred[0])\n",
    "#cv2.putText(img, \"Dataflair _ _ _ \", (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))\n",
    "cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))\n",
    "cv2.imshow('mat',img)\n",
    "\n",
    "\n",
    "while (1):\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\n",
    "    \"This image most likely is {} with a {:.2f} percent confidence.\".format(categories[list(categories.keys())[np.argmax(score)]], 100*np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59348d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
